<!doctype html>

<html>
<head>
	<meta charset="utf-8">
	<title>Qinqing Zheng</title>
	<meta name="author" content="Qinqing Zheng"/>
	<meta name="viewport" content="width=device-width; initial-scale=1.0">
	<link rel="stylesheet" type="text/css" href="home.css">
	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
</head>

<body>
	<div class="container">
		<div class="section profile">
            <div class="profile-img">
                <div class="profile-img-wrap">
                    <img src="qinqing.jpg" title="Qinqing" alt="Qinqing Profile Image"/>
                </div>
            </div>
            <div class="profile-info">
                <h1>Qinqing Zheng</h1>
                <p> University of Pennsylvania </p>
                <p> zhengqinqing (at) gmail (dot) com </p>
                <p>
                    <a href="https://scholar.google.com/citations?hl=en&user=Jwnl3v0AAAAJ"> Google Scholar </a>
                    &nbsp
                    <a href="https://github.com/enosair/"> GitHub </a> </p>
            </div>
        </div>

        <div class="section">

    		<h2 id="bio">About</h2>
    		<ul>
                <li>
                I'm a postdoc researcher in the Statistics Department, Wharton School,
                University of Pennsylvania.
                </li>

                <li>
                Prior to Penn, I was a research scientist in Facebook from 2017 to 2019.
                <br> <br>
                With my teammates, I help Facebook build its distributed training system
                for training deep personalization and recommendation models. My work
                concentrates on distributed optimization algorithms and system
                architecture design.
                </li>

                <li>
                I received my PhD degree in CS at the University of Chicago in 2017. I
                was very fortunate to be advised by Prof. John Lafferty.
                <br> <br>
                During my PhD, I worked in the intersection of machine learning,
                optimization and statistics.  My research centered around developing
                novel computationally efficient methods with theoretical guarantees for
                challenging machine learning problems, with an emphasis on finding exact
                solutions for nonconvex problems.
                </li>

                <li>
                Earlier, I got my master degree in Max Planck Institute for Informatics
                and my bachelor degree in Zhejiang University. </li>
    		</ul>
        </div>

        <div class="section">

    		<h2 id="publication">Papers</h2>
    		<ul>
                <li>
                    <p>
                        <strong> Near-Optimal Confidence Sequences for Bounded Random Variables </strong><br/>
                        Arun Kumar Kuchibhotla*, <strong>Qinqing Zheng*</strong> (*Equal contribution) <br/>
                        International Conference on Machine Learning (ICML) 2021 <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2006.05022"
                            target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/bentkus_conf_seq">[code]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> A Theorem of the Alternative for Personalized Federated Learning </strong></br>
                        Shuxiao Chen, <strong>Qinqing Zheng</strong>,  Qi Long, Weijie Su<br/>
                        Submitted. <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2103.01901"
                            target="_blank">[paper]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> Federated \(f\)-Differential Privacy </strong></br>
                        <strong>Qinqing Zheng</strong>, Shuxiao Chen, Qi Long, Weijie Su<br/>
                        International Conference on Artificial Intelligence and
                        Statistics (AISTATS) 2021<br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2102.11158"
                            target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/federated_fdp">[code]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion</strong></br>
                        <strong>Qinqing Zheng</strong>, Jinshuo Dong, Qi Long, Weijie Su<br/>
                        International Conference on Machine Learning (ICML) 2020 <br/>
    				    <a class="paper-pub" href="https://arxiv.org/abs/2003.04493"
                        target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/gdp-edgeworth">[code]</a>
                    </p>
    			</li>


                <li>
                    <p><strong>
                        ShadowSync: Performing Synchronization in the Background for Highly Scalable Distributed Training
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, Bor-Yiing Su, Jiyan Yang, Alisson Azzolini, Qiang Wu, Ou Jin, Shri Karandikar, Hagay Lupesko, Liang Xiong, Eric Zhou
                    <br/>
                    Submitted.
                    <br/>
    				<a class="paper-pub" href="https://arxiv.org/abs/2003.03477"
                        target="_blank">[paper]</a>
    			</li>


                <li>
                    <p><strong>
                        Convergence Analysis for Rectangular Matrix Completion Using Burer-Monteiro Factorization and Gradient Descent
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, John Lafferty
                    <br/>
    				<a class="paper-pub" href="https://arxiv.org/abs/1605.07051"
                        target="_blank">[paper]</a>
    			</li>

                <li>
                    <p><strong>
                        A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, John Lafferty
                    <br/>
                    Advances in Neural Information Processing Systems (NeurIPS) 2015
                    </br>
    				<a class="paper-pub" href="http://arxiv.org/abs/1506.06081"
                        target="_blank">[paper]</a>
                    <a href="./sdp_nips15.pdf">[poster]</a>
    			</li>

                <li>
                    <p><strong>
                    Interpolating Convex and Non-Convex Tensor Decompositions via the Subspace Norm
                    </strong><br/>
                        <strong> Qinqing Zheng </strong>, Ryota Tomioka
                    <br/>
                    Advances in Neural Information Processing Systems (NeurIPS) 2015
                    </br>
    				<a class="paper-pub" href="http://arxiv.org/abs/1503.05479"
                        target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/tensor-subspace-norm">[code]</a>
                        <a href="./tensor_nips15.pdf">[poster]</a>
    			</li>
    		</ul>
        </div>

        <!--
        <div class="section">
    		<h2 id="TA">Teaching Assistant</h2>
    		<ul>
                <li>CMSC 12100 <span class="course-name">Computer Science with Applications I</span>, 2013, 2014 </li>
    		    <li> CMSC 12200 <span class="course-name">Computer Science with
                    Applications II</span>, 2015, 2016 </li>
                <li>CMSC 25025 / STAT 37601 <span class="course-name">Machine Learning
                    and Large Scale Data Analysis</span>, 2014, 2017 </li>
                <li>CMSC 25400 <span class="course-name">Machine Learning</span>, 2014  </li>
            </ul>
        </div>
        -->


        <div class="section">
    		<h2 id="talks">Talks</h2>
    		<ul>

          <li> Ming Hesieh Institute Series on Mathematical Foundations of Learning
          from Signals and Data, USC, Dec 2016 </li>
          <li> SILO Seminar Series, University of Wisconsin Madison, Jan 2017 </li>
          <li> Microsoft Cambridge Research Seminar, UK, March 2017 </li>
          <li> Minisymposium on Non-Convex Optimization for Low Complexity Models:
          Theory and Applications, SIAM Optimization Conference, May 2017 </li>
       </ul>
        </div>

        <div class="section">
    		<h2 id="reviewer">Review</h2>
    		<ul>
                <li> Conference: ICML, NeurIPS, AISTATS, ICLR </li>
          <li> Journal: Journal of Machine Learning Research (Editorial Board Reviewer), IEEE Transactions on Signal Processing, Annals of Statistics </li>
            </ul>
        </div>



        <!--
        <div class="footer"> Last updated Feb 2021 </div>
        -->
    </div>

</body>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new
    Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-48448003-2', 'auto');
    ga('send', 'pageview');

</script>

</html>

